{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcda3dbf",
   "metadata": {},
   "source": [
    "# LoCS Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a505a",
   "metadata": {},
   "source": [
    "## Let's build LoCS from scratch\n",
    "\n",
    "We will now create a simplified LoCS network, without many of the bells and whistles that are part of the final network. Namely, we will remove the Neural Relational Inference (NRI) VAE architecture, as it is orthogonal to LoCS. Furthermore, we will remove the anisotropic linear filters and use MLPs instead.\n",
    "\n",
    "![Simple LoCS Architecture](assets/img/simple_equivariant_locs_pipeline.png)\n",
    "\n",
    "The following code is meant to be almost self-contained; it depends only on PyTorch, and a few TorchGeometric functions for message passing.\n",
    "It is also mostly targeted towards readability and understanding the core ideas. Towards this goal, we have unified many functions that had different implementations for 2 and 3 dimensions. This may come at a speed cost, but it has greatly simplified the source code. The (self-contained) source code is now ~170 lines of code for the actual LoCS operations, plus ~150 for the full model that includes the graph network and some training/evaluation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d33567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6a6d5",
   "metadata": {},
   "source": [
    "The following functions define the geometric operations we use, including conversions from euler angles to rotation matrices and vice-versa, and conversions from cartesian to polar/spherical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733bb657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(ndim, theta, phi=None, psi=None, /):\n",
    "    \"\"\"\n",
    "    theta, phi, psi: yaw, pitch, roll\n",
    "\n",
    "    NOTE: We assume that each angle is has the shape [dims] x 1\n",
    "    \"\"\"\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    if ndim == 2:\n",
    "        R = torch.stack([torch.cat([cos_theta, -sin_theta], -1),\n",
    "                         torch.cat([sin_theta, cos_theta], -1)], -2)\n",
    "        return R\n",
    "    cos_phi = torch.cos(phi)\n",
    "    sin_phi = torch.sin(phi)\n",
    "    R = torch.stack([\n",
    "            torch.cat([cos_phi * cos_theta, -sin_theta, sin_phi * cos_theta], -1),\n",
    "            torch.cat([cos_phi * sin_theta, cos_theta, sin_phi * sin_theta], -1),\n",
    "            torch.cat([-sin_phi, torch.zeros_like(cos_theta), cos_phi], -1)], -2)\n",
    "    return R\n",
    "\n",
    "\n",
    "def cart_to_n_spherical(x, symmetric_theta=False):\n",
    "    \"\"\"Transform Cartesian to n-Spherical Coordinates\n",
    "\n",
    "    NOTE: Not tested thoroughly for n > 3\n",
    "\n",
    "    Math convention, theta: azimuth angle, angle in x-y plane\n",
    "\n",
    "    x: torch.Tensor, [dims] x D\n",
    "    return rho, theta, phi\n",
    "    \"\"\"\n",
    "    ndim = x.size(-1)\n",
    "\n",
    "    rho = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
    "\n",
    "    theta = torch.atan2(x[..., [1]], x[..., [0]])\n",
    "    if not symmetric_theta:\n",
    "        theta = theta + (theta < 0).type_as(theta) * (2 * np.pi)\n",
    "\n",
    "    if ndim == 2:\n",
    "        return rho, theta\n",
    "\n",
    "    cum_sqr = (rho if ndim == 3\n",
    "               else torch.sqrt(torch.cumsum(torch.flip(x ** 2, [-1]), dim=-1))[..., 2:])\n",
    "    EPS = 1e-7\n",
    "    phi = torch.acos(\n",
    "        torch.clamp(x[..., 2:] / (cum_sqr + EPS), min=-1.0, max=1.0)\n",
    "    )\n",
    "\n",
    "    return rho, theta, phi\n",
    "\n",
    "\n",
    "def velocity_to_rotation_matrix(vel):\n",
    "    num_dims = vel.size(-1)\n",
    "    orientations = cart_to_n_spherical(vel)[1:]\n",
    "    R = rotation_matrix(num_dims, *orientations)\n",
    "    return R\n",
    "\n",
    "\n",
    "def rotation_matrix_to_euler(R, num_dims, normalize=True):\n",
    "    \"\"\"Convert rotation matrix to euler angles\n",
    "\n",
    "    In 3 dimensions, we follow the ZYX convention\n",
    "    \"\"\"\n",
    "    if num_dims == 2:\n",
    "        euler = torch.atan2(R[..., 1, [0]], R[..., 0, [0]])\n",
    "    else:\n",
    "        euler = torch.stack([\n",
    "            torch.atan2(R[..., 1, 0], R[..., 0, 0]),\n",
    "            torch.asin(-R[..., 2, 0]),\n",
    "            torch.atan2(R[..., 2, 1], R[..., 2, 2]),\n",
    "        ], -1)\n",
    "\n",
    "    if normalize:\n",
    "        euler = euler / np.pi\n",
    "    return euler\n",
    "\n",
    "\n",
    "def rotate(x, R):\n",
    "    return torch.einsum('...ij,...j->...i', R, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486c400",
   "metadata": {},
   "source": [
    "#### Localizer\n",
    "\n",
    "We will now define the Localizer, the function that transforms our position-velocity inputs from the global coordinate frame to local coordinate frames. This module also computes the rotation matrices that will be used to perform the inverse transformations from the local coordinate frames to the global coordinate frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Localizer(nn.Module):\n",
    "    def __init__(self, num_objects: int, num_dims: int = 2):\n",
    "        super().__init__()\n",
    "        self.num_objects = num_objects\n",
    "        self.send_edges, self.recv_edges = torch.where(\n",
    "            ~torch.eye(self.num_objects, dtype=bool))\n",
    "\n",
    "        self.num_dims = num_dims\n",
    "\n",
    "        self.num_orientations = self.num_dims * (self.num_dims - 1) // 2\n",
    "        # Relative features include: positions, orientations, positions in\n",
    "        # spherical coordinates, and velocities\n",
    "        self.num_relative_features = 3 * self.num_dims + self.num_orientations\n",
    "\n",
    "    def set_edge_index(self, send_edges, recv_edges):\n",
    "        self.send_edges = send_edges\n",
    "        self.recv_edges = recv_edges\n",
    "\n",
    "    def sender_receiver_features(self, x):\n",
    "        batch_range = torch.arange(x.size(0), device=x.device).unsqueeze(-1)\n",
    "        x_j = x[batch_range, self.send_edges]\n",
    "        x_i = x[batch_range, self.recv_edges]\n",
    "        return x_j, x_i\n",
    "\n",
    "    def canonicalize_inputs(self, inputs):\n",
    "        if inputs.size(-1) != 2 * self.num_dims:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        vel = inputs[..., self.num_dims:]\n",
    "        R = velocity_to_rotation_matrix(vel)\n",
    "        Rinv = R.transpose(-1, -2)\n",
    "\n",
    "        canon_vel = rotate(vel, Rinv)\n",
    "        canon_inputs = torch.cat([torch.zeros_like(canon_vel), canon_vel], dim=-1)\n",
    "\n",
    "        return canon_inputs, R\n",
    "\n",
    "    def create_edge_attr(self, x):\n",
    "        x_j, x_i = self.sender_receiver_features(x)\n",
    "\n",
    "        # We approximate orientations via the velocity vector\n",
    "        R = velocity_to_rotation_matrix(x_i[..., self.num_dims:])\n",
    "        R_inv = R.transpose(-1, -2)\n",
    "\n",
    "        # Positions\n",
    "        relative_positions = x_j[..., :self.num_dims] - x_i[..., :self.num_dims]\n",
    "        rotated_relative_positions = rotate(relative_positions, R_inv)\n",
    "\n",
    "        # Orientations\n",
    "        send_R = velocity_to_rotation_matrix(x_j[..., self.num_dims:])\n",
    "        rotated_orientations = R_inv @ send_R\n",
    "        rotated_euler = rotation_matrix_to_euler(rotated_orientations, self.num_dims)\n",
    "\n",
    "        # Rotated relative positions in spherical coordinates\n",
    "        node_distance = torch.norm(relative_positions, p=2, dim=-1, keepdim=True)\n",
    "        spherical_relative_positions = torch.cat(\n",
    "            cart_to_n_spherical(rotated_relative_positions, symmetric_theta=True)[1:], -1)\n",
    "\n",
    "        # Velocities\n",
    "        rotated_velocities = rotate(x_j[..., self.num_dims:], R_inv)\n",
    "\n",
    "        edge_attr = torch.cat([\n",
    "            rotated_relative_positions,\n",
    "            rotated_euler,\n",
    "            node_distance,\n",
    "            spherical_relative_positions,\n",
    "            rotated_velocities,\n",
    "        ], -1)\n",
    "        return edge_attr\n",
    "\n",
    "    def forward(self, x):\n",
    "        rel_feat, R = self.canonicalize_inputs(x)\n",
    "        edge_attr = self.create_edge_attr(x)\n",
    "\n",
    "        batch_range = torch.arange(x.size(0), device=x.device).unsqueeze(-1)\n",
    "        edge_attr = torch.cat([edge_attr, rel_feat[batch_range, self.recv_edges]], -1)\n",
    "        return rel_feat, R, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47438bc4",
   "metadata": {},
   "source": [
    "#### Globalizer\n",
    "\n",
    "Next, we define the Globalizer, that transforms outputs to the global coordinate frame. It is a very simple module that rotates the predicted positions and velocities (or rather the difference in positions and velocities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Globalizer(nn.Module):\n",
    "    def __init__(self, num_dims: int = 2):\n",
    "        super().__init__()\n",
    "        self.num_dims = num_dims\n",
    "\n",
    "    def forward(self, x, R):\n",
    "        return torch.cat(\n",
    "            [rotate(x[..., :self.num_dims], R),\n",
    "             rotate(x[..., self.num_dims:], R)], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891938ff",
   "metadata": {},
   "source": [
    "#### GNN\n",
    "\n",
    "And that is it! The Localizer-Globalizer combination comprises the core of LoCS, since LoCS can be combined with many graph network architectures.\n",
    "\n",
    "In the following, we will create a simple GNN to showcase its usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b49940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLoCS(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        # Model Params\n",
    "        self.network = (MarkovNetwork(params)\n",
    "                        if params.get('network_type', None) == 'markov'\n",
    "                        else RecurrentNetwork(params))\n",
    "\n",
    "        # Training params\n",
    "        self.prior_variance = params.get('prior_variance')\n",
    "        self.kl_coef = 1.0\n",
    "\n",
    "    def calculate_loss(self, inputs, return_logits=False):\n",
    "        network_hidden = self.network.get_initial_hidden(inputs)\n",
    "        num_time_steps = inputs.size(1)\n",
    "        all_predictions = []\n",
    "\n",
    "        # We train using teacher forcing\n",
    "        for step in range(num_time_steps-1):\n",
    "            current_inputs = inputs[:, step]\n",
    "            predictions, network_hidden = self.network(current_inputs, network_hidden)\n",
    "            all_predictions.append(predictions)\n",
    "        all_predictions = torch.stack(all_predictions, dim=1)\n",
    "        target = inputs[:, 1:, :, :]\n",
    "        loss_nll = self.nll(all_predictions, target)\n",
    "        loss = loss_nll.mean()\n",
    "\n",
    "        if return_logits:\n",
    "            return loss, loss_nll, torch.FloatTensor([0.0]), None, all_predictions\n",
    "        else:\n",
    "            return loss, loss_nll, torch.FloatTensor([0.0])\n",
    "\n",
    "    def predict_future(self, inputs, prediction_steps, return_everything=False):\n",
    "        burn_in_timesteps = inputs.size(1)\n",
    "        network_hidden = self.network.get_initial_hidden(inputs)\n",
    "        all_predictions = []\n",
    "        for step in range(burn_in_timesteps-1):\n",
    "            current_inputs = inputs[:, step]\n",
    "            predictions, network_hidden = self.network(current_inputs, network_hidden)\n",
    "            if return_everything:\n",
    "                all_predictions.append(predictions)\n",
    "        predictions = inputs[:, burn_in_timesteps-1]\n",
    "        for step in range(prediction_steps):\n",
    "            predictions, network_hidden = self.network(predictions, network_hidden)\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "        predictions = torch.stack(all_predictions, dim=1)\n",
    "        return predictions\n",
    "\n",
    "    def nll(self, preds, target):\n",
    "        return self.nll_gaussian(preds, target, self.prior_variance)\n",
    "\n",
    "    @staticmethod\n",
    "    def nll_gaussian(preds, target, variance):\n",
    "        neg_log_p = ((preds - target) ** 2 / (2 * variance))\n",
    "        const = 0.5 * np.log(2 * np.pi * variance)\n",
    "        return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        \n",
    "        \n",
    "class MarkovNetwork(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.gnn = GNN(params)\n",
    "        self.localizer = Localizer(params['num_vars'], params['num_dims'])\n",
    "        self.globalizer = Globalizer(params['num_dims'])\n",
    "\n",
    "    def get_initial_hidden(self, inputs):\n",
    "        return None\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        \"\"\"inputs shape: [batch_size, num_objects, input_size]\"\"\"\n",
    "        # Global to Local\n",
    "        rel_feat, Rinv, edge_attr, _ = self.localizer(inputs)\n",
    "\n",
    "        # GNN\n",
    "        pred = self.gnn(rel_feat, edge_attr)\n",
    "\n",
    "        # Local to Global\n",
    "        pred = self.globalizer(pred, Rinv)\n",
    "\n",
    "        # Predict position/velocity difference and integrate\n",
    "        outputs = inputs + pred\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        outputs = self._forward(inputs)\n",
    "        return outputs, None\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.num_objects = params['num_vars']\n",
    "        input_size = params['input_size']\n",
    "        hidden_size = params['decoder_hidden']\n",
    "        out_size = input_size\n",
    "\n",
    "        dropout_prob = params['decoder_dropout']\n",
    "\n",
    "        self.send_edges, self.recv_edges = torch.where(\n",
    "            ~torch.eye(self.num_objects, dtype=bool))\n",
    "\n",
    "        self.use_3d = params.get('use_3d', False)\n",
    "        self.num_relative_features = 12 if self.use_3d else 7\n",
    "\n",
    "        # Neural Network Layers\n",
    "        self.edge_filter = nn.Sequential(\n",
    "            nn.Linear(self.num_relative_features+input_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "        self.res1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.out_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(hidden_size, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, edge_attr):\n",
    "        \"\"\"\n",
    "        inputs shape: [batch_size, num_objects, input_size]\n",
    "        \"\"\"\n",
    "        # Edge embeddings\n",
    "        edge_attr = self.edge_filter(edge_attr)\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = scatter(\n",
    "            edge_attr, self.recv_edges.to(inputs.device), dim=1,\n",
    "            reduce='mean').contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = agg_msgs + self.res1(inputs)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = self.out_mlp(aug_inputs)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6064626b",
   "metadata": {},
   "source": [
    "Finally, we define a recurrent recoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d36039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.hidden_size = params['decoder_hidden']\n",
    "\n",
    "        self.gnn = RecurrentGNN(params)\n",
    "        self.localizer = Localizer(params['num_vars'], params['num_dims'])\n",
    "        self.globalizer = Globalizer(params['num_dims'])\n",
    "\n",
    "    def get_initial_hidden(self, inputs):\n",
    "        return torch.zeros(inputs.size(0), inputs.size(2), self.hidden_size, device=inputs.device)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        inputs size: [batch, num_objects, input_size]\n",
    "        hidden size: [batch, num_objects, hidden_size]\n",
    "        \"\"\"\n",
    "        rel_feat, Rinv, edge_attr, _ = self.localizer(inputs)\n",
    "\n",
    "        pred = self.gnn(rel_feat, edge_attr, hidden)\n",
    "\n",
    "        pred = self.globalizer(pred, Rinv)\n",
    "\n",
    "        outputs = inputs + pred\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class RecurrentGNN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.num_objects = params['num_vars']\n",
    "        input_size = params['input_size']\n",
    "        hidden_size = params['decoder_hidden']\n",
    "        out_size = params['input_size']\n",
    "        self.dropout_prob = params['decoder_dropout']\n",
    "\n",
    "        self.send_edges, self.recv_edges = torch.where(\n",
    "            ~torch.eye(self.num_objects, dtype=bool))\n",
    "\n",
    "        self.use_3d = params.get('use_3d', False)\n",
    "        self.num_relative_features = 12 if self.use_3d else 7\n",
    "\n",
    "        self.msg_mlp = nn.Sequential(\n",
    "            nn.Linear(2*hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(self.dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.present_msg_mlp = nn.Sequential(\n",
    "            nn.Linear(self.num_relative_features+input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.res_mlp =  = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_r = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.input_i = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.input_n = nn.Linear(input_size, hidden_size, bias=True)\n",
    "\n",
    "        self.hidden_r = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.hidden_i = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.hidden_h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "        self.out_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(hidden_size, out_size),\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, inputs, edge_attr, hidden):\n",
    "        \"\"\"\n",
    "        inputs size: [batch, num_objects, input_size]\n",
    "        edge_attr size: [batch, num_edges, num_edge_features]\n",
    "        hidden size: [batch, num_objects, hidden_size]\n",
    "        \"\"\"\n",
    "\n",
    "        # node2edge\n",
    "        receivers = hidden[:, self.recv_edges]\n",
    "        senders = hidden[:, self.send_edges]\n",
    "\n",
    "        # hidden_messages: [batch, num_edges, 2 * hidden_size]\n",
    "        hidden_messages = torch.cat([receivers, senders], dim=-1)\n",
    "        hidden_messages = self.msg_mlp(hidden_messages)\n",
    "        hidden_node_emb = scatter(hidden_messages, self.recv_edges.cuda(), dim=1, reduce='mean').contiguous()\n",
    "\n",
    "        # Present messages\n",
    "        present_messages = self.present_msg_mlp(edge_attr)\n",
    "        present_node_emb = scatter(present_messages, self.recv_edges.cuda(), dim=1, reduce='mean').contiguous()\n",
    "        present_node_emb = self.res_mlp(inputs) + present_node_emb\n",
    "\n",
    "        # GRU-style gated aggregation\n",
    "        r = torch.sigmoid(self.input_r(present_node_emb) + self.hidden_r(hidden_node_emb))\n",
    "        i = torch.sigmoid(self.input_i(present_node_emb) + self.hidden_i(hidden_node_emb))\n",
    "        n = torch.tanh(self.input_n(present_node_emb) + r*self.hidden_h(hidden_node_emb))\n",
    "        hidden = (1 - i) * n + i * hidden\n",
    "\n",
    "        # Output MLP\n",
    "        pred = self.out_mlp(hidden)\n",
    "        return pred, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa98f72",
   "metadata": {},
   "source": [
    "### Extra: A Torch Geometric Layer for LoCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class PyGNetwork(MessagePassing):\n",
    "    def __init__(self, params):\n",
    "        super().__init__(aggr='mean')\n",
    "        self.num_objects = params['num_vars']\n",
    "        input_size = params['input_size']\n",
    "        hidden_size = params['decoder_hidden']\n",
    "        out_size = input_size\n",
    "\n",
    "        dropout_prob = params['decoder_dropout']\n",
    "\n",
    "        self.edge_index = torch.where(\n",
    "            ~torch.eye(self.num_objects, dtype=bool))\n",
    "\n",
    "        self.use_3d = params.get('use_3d', False)\n",
    "        self.num_relative_features = 12 if self.use_3d else 7\n",
    "\n",
    "        # Neural Network Layers\n",
    "        self.edge_filter = nn.Sequential(\n",
    "            nn.Linear(self.num_relative_features+input_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "        self.res1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.out_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(hidden_size, out_size),\n",
    "        )\n",
    "\n",
    "        self.localizer = Localizer(params['num_vars'], params['num_dims'])\n",
    "        self.globalizer = Globalizer(params['num_dims'])\n",
    "\n",
    "    def get_initial_hidden(self, inputs):\n",
    "        return None\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs shape: [batch_size, num_objects, input_size]\n",
    "        \"\"\"\n",
    "        # Global to Local\n",
    "        rel_feat, Rinv, edge_attr, _ = self.localizer(inputs)\n",
    "\n",
    "        pred = self.propagate(self.edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        pred = pred + self.res1(rel_feat)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = self.out_mlp(pred)\n",
    "\n",
    "        # Local to Global\n",
    "        pred = self.globalizer(pred, Rinv)\n",
    "\n",
    "        # Predict position/velocity difference and integrate\n",
    "        outputs = inputs + pred\n",
    "        return outputs\n",
    "\n",
    "    def message(self, edge_attr):\n",
    "        edge_attr = self.edge_filter(edge_attr)\n",
    "        return edge_attr\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        outputs = self._forward(inputs)\n",
    "        return outputs, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
